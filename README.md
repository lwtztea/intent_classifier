## Модель классификации пользовательских интентов

### Архитектуры и результаты

Я опробовала различные подходы: как классический ML, так и DL. Оказалось, что модели, такие как *random forest*, *naive bayes*, *linear support vector classifier* и др., показывают намного лучшее качество, чем модели на основе нейронных сетей. К примеру, для *knn*, который имел самый плохой результат среди моделей первой группы, *f1_score* составлял 0.811, в то время как предобученный Берт с файн-тьюнингом смог достичь только 0.591.

### Структура репозитория

В директории *jupyter notebook* находится три блокнота. В *experiment...* и *different approaches...* описан процесс эксперимента, начиная от небольшой предобработки данных, далее построение и обучение моделей. Также в блокнотах приведена оценка качества на тестовой выборке. В *example...* можно увидеть post-запрос, ответом на который являются категории подаваемых текстов (сейчас работает только при локальном запуске app.py, но в целом можно залить приложение на herokuapp и тогда его будет удобней тестировать).

В основной части репозитория содержатся файлы с двумя различными моделями (Берт и SVM-классификатор), различными вспомогательными функциями *utils.py* и самим rest сервисом. В приложении для классификации интентов используется SVC, поскольку среди всех моделей он показал наилучшее качество (f1_score=0.894).

### Тестирование приложения

Для начала нужно запустить у себя локально докер-контейнер:
```sh
docker run -p 5000:5000 lwtztea/intent_classifier
```
Это займёт некоторое время (так что успеете быстро заварить себе чаёк), после чего можно отправлять запросы в новом консольном окне:
```sh
curl --header "Content-Type: application/json" --data '{"query":["where is my card?"]}' host:5000/predict
```
Адрес хоста будет указан в логах запуска контейнера.
